{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing All Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras import mixed_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU and Mixed Precision Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable mixed precision for improved performance and reduced memory usage (optional)\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Configure GPU memory growth to avoid pre-allocating all VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_WEIGHT = 1e4\n",
    "STYLE_WEIGHT = 1e-2\n",
    "TV_WEIGHT = 30\n",
    "STEPS = 1000\n",
    "LEARNING_RATE = 0.02\n",
    "MAX_DIM = 384"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Image Handling Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path, max_dim=MAX_DIM):\n",
    "    img = PIL.Image.open(path).convert('RGB')\n",
    "    img.thumbnail((max_dim, max_dim))\n",
    "    img = np.array(img)\n",
    "    img = tf.keras.applications.vgg19.preprocess_input(img)\n",
    "    return tf.expand_dims(tf.convert_to_tensor(img, dtype=tf.float16), 0)\n",
    "\n",
    "def deprocess_img(processed_img):\n",
    "    img = processed_img.numpy().squeeze()\n",
    "    img += [103.939, 116.779, 123.68]\n",
    "    img = img[:, :, ::-1]\n",
    "    return np.clip(img, 0, 255).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    content_layer = 'block5_conv2'\n",
    "    style_layers = [f'block{i}_conv1' for i in range(1, 6)]\n",
    "    outputs = [vgg.get_layer(content_layer).output] + [vgg.get_layer(layer).output for layer in style_layers]\n",
    "    return tf.keras.Model(vgg.input, outputs)\n",
    "\n",
    "def gram_matrix(tensor):\n",
    "    \"\"\"Compute the Gram matrix.\"\"\"\n",
    "    channels = int(tensor.shape[-1])\n",
    "    a = tf.reshape(tensor, [-1, channels])\n",
    "    return tf.matmul(a, a, transpose_a=True) / tf.cast(tf.shape(a)[0], tf.float16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(content, generated):\n",
    "    return tf.reduce_mean(tf.square(tf.cast(content, tf.float16) - tf.cast(generated, tf.float16)))\n",
    "\n",
    "def style_loss(style, generated):\n",
    "    return tf.reduce_mean(tf.square(tf.cast(style, tf.float16) - tf.cast(generated, tf.float16)))\n",
    "\n",
    "def total_variation_loss(image):\n",
    "    x_diff = image[:, 1:, :, :] - image[:, :-1, :, :]\n",
    "    y_diff = image[:, :, 1:, :] - image[:, :, :-1, :]\n",
    "    return tf.reduce_sum(tf.abs(x_diff)) + tf.reduce_sum(tf.abs(y_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Load Images and Initialize Generated Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = load_img('content.jpg')\n",
    "style_image = load_img('style.jpg')\n",
    "# Ensure generated image is float16\n",
    "generated_image = tf.Variable(content_image, dtype=tf.float16)\n",
    "\n",
    "# Get model\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Extract Feature Targets from the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_target = tf.cast(model(content_image)[0], tf.float16) \n",
    "style_targets = [tf.cast(gram_matrix(style_output), tf.float16) for style_output in model(style_image)[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Optimizer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Training Step (compiled with tf.function for performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(generated_image, content_target, style_targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(tf.cast(generated_image, tf.float16))\n",
    "        generated_content = tf.cast(outputs[0], tf.float16)\n",
    "        generated_styles = [tf.cast(gram_matrix(style_output), tf.float16) for style_output in outputs[1:]]  # Cast\n",
    "\n",
    "        # Compute losses\n",
    "        c_loss = content_loss(content_target, generated_content)\n",
    "        s_loss = tf.add_n([style_loss(style_target, gen_style) for style_target, gen_style in zip(style_targets, generated_styles)]) / len(style_targets)\n",
    "        tv_loss = total_variation_loss(generated_image)\n",
    "\n",
    "        total_loss = CONTENT_WEIGHT * c_loss + STYLE_WEIGHT * s_loss + TV_WEIGHT * tv_loss\n",
    "\n",
    "    gradients = tape.gradient(total_loss, generated_image)\n",
    "    optimizer.apply_gradients([(gradients, generated_image)])\n",
    "    return total_loss, c_loss, s_loss, tv_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Total Loss=nan, Content Loss=0.00e+00, Style Loss=nan, TV Loss=inf\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for step in range(STEPS):\n",
    "    total_loss, c_loss, s_loss, tv_loss = train_step(generated_image, content_target, style_targets)\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step}: Total Loss={total_loss:.2e}, Content Loss={c_loss:.2e}, Style Loss={s_loss:.2e}, TV Loss={tv_loss:.2e}\")\n",
    "print(f\"Total time: {time.time()-start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Display and Save the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = deprocess_img(generated_image)\n",
    "plt.imshow(result)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "common",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
